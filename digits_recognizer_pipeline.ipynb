{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da13c87-aed3-4c3a-bac8-1807ded41b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/e5076f7c-8815-4eb9-81e2-223e31a65748\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/ff09ee4c-feac-4d47-b2eb-d177b7696c00\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kfp import dsl, compiler\n",
    "from typing import NamedTuple\n",
    "from kfp.dsl import Input, Output, Dataset, Model, Artifact, component\n",
    "\n",
    "@component(base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
    "def get_data_batch() -> NamedTuple('Outputs', [('datapoints_training', float),('datapoints_test', float),('dataset_version', str)]):\n",
    "    from tensorflow import keras\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import json\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"100.65.11.110:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"mnist.npz\",\"/tmp/mnist.npz\")\n",
    "\n",
    "    def load_data():\n",
    "        with np.load(\"/tmp/mnist.npz\", allow_pickle=True) as f:\n",
    "            x_train, y_train = f[\"x_train\"], f[\"y_train\"]\n",
    "            x_test, y_test = f[\"x_test\"], f[\"y_test\"]\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "    np.save(\"/tmp/x_train.npy\",x_train)\n",
    "    minio_client.fput_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "\n",
    "    np.save(\"/tmp/y_train.npy\",y_train)\n",
    "    minio_client.fput_object(minio_bucket,\"y_train\",\"/tmp/y_train.npy\")\n",
    "\n",
    "    np.save(\"/tmp/x_test.npy\",x_test)\n",
    "    minio_client.fput_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "\n",
    "    np.save(\"/tmp/y_test.npy\",y_test)\n",
    "    minio_client.fput_object(minio_bucket,\"y_test\",\"/tmp/y_test.npy\")\n",
    "\n",
    "    dataset_version = \"1.0\"\n",
    "\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "    from collections import namedtuple\n",
    "    divmod_output = namedtuple('Outputs', ['datapoints_training', 'datapoints_test', 'dataset_version'])\n",
    "    return [float(x_train.shape[0]),float(x_test.shape[0]),dataset_version]\n",
    "\n",
    "@component(base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
    "def get_latest_data():\n",
    "    print(\"Adding latest data\")\n",
    "\n",
    "@component(base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
    "def reshape_data():\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"100.65.11.110:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "    x_train = np.load(\"/tmp/x_train.npy\")\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "    x_test = np.load(\"/tmp/x_test.npy\")\n",
    "\n",
    "    x_train = x_train.reshape(-1,28,28,1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "\n",
    "    np.save(\"/tmp/x_train.npy\",x_train)\n",
    "    minio_client.fput_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "\n",
    "    np.save(\"/tmp/x_test.npy\",x_test)\n",
    "    minio_client.fput_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "\n",
    "@component(base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\")\n",
    "def model_building(no_epochs: int = 1, optimizer: str = \"adam\"):\n",
    "    from tensorflow import keras\n",
    "    import tensorflow as tf\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"100.65.11.110:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "        keras.layers.MaxPool2D(2, 2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    stringlist = []\n",
    "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "    metric_model_summary = \"\\n\".join(stringlist)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"x_train\",\"/tmp/x_train.npy\")\n",
    "    x_train = np.load(\"/tmp/x_train.npy\")\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"y_train\",\"/tmp/y_train.npy\")\n",
    "    y_train = np.load(\"/tmp/y_train.npy\")\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=no_epochs, batch_size=20)\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"x_test\",\"/tmp/x_test.npy\")\n",
    "    x_test = np.load(\"/tmp/x_test.npy\")\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"y_test\",\"/tmp/y_test.npy\")\n",
    "    y_test = np.load(\"/tmp/y_test.npy\")\n",
    "\n",
    "    model_loss, model_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "    test_predictions = model.predict(x_test)\n",
    "    test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "    confusion_matrix = tf.math.confusion_matrix(labels=y_test, predictions=test_predictions)\n",
    "    confusion_matrix = confusion_matrix.numpy()\n",
    "    vocab = list(np.unique(y_test))\n",
    "    data = [(vocab[target_index], vocab[predicted_index], count)\n",
    "            for target_index, target_row in enumerate(confusion_matrix)\n",
    "            for predicted_index, count in enumerate(target_row)]\n",
    "\n",
    "    df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n",
    "    cm_csv = df_cm.to_csv(header=False, index=False)\n",
    "\n",
    "    keras.models.save_model(model, \"/tmp/detect-digits\")\n",
    "\n",
    "    def upload_local_directory_to_minio(local_path, bucket_name, minio_path):\n",
    "        import os, glob\n",
    "        assert os.path.isdir(local_path)\n",
    "        for local_file in glob.glob(local_path + '/**'):\n",
    "            local_file = local_file.replace(os.sep, \"/\")\n",
    "            if not os.path.isfile(local_file):\n",
    "                upload_local_directory_to_minio(local_file, bucket_name, f\"{minio_path}/{os.path.basename(local_file)}\")\n",
    "            else:\n",
    "                remote_path = os.path.join(minio_path, local_file[1 + len(local_path):]).replace(os.sep, \"/\")\n",
    "                minio_client.fput_object(bucket_name, remote_path, local_file)\n",
    "\n",
    "    upload_local_directory_to_minio(\"/tmp/detect-digits\", minio_bucket, \"models/detect-digits/1/\")\n",
    "    print(\"Saved model to minIO\")\n",
    "\n",
    "    from collections import namedtuple\n",
    "    output = namedtuple('output', ['mlpipeline_ui_metadata', 'mlpipeline_metrics'])\n",
    "    return output(json.dumps(metadata), json.dumps(metrics))\n",
    "\n",
    "@component(base_image=\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\",\n",
    "          packages_to_install=['kserve==0.8.0.1'])\n",
    "def model_serving():\n",
    "    from kubernetes import client\n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import utils\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1TFServingSpec\n",
    "    from datetime import datetime\n",
    "\n",
    "    namespace = utils.get_default_target_namespace()\n",
    "    now = datetime.now()\n",
    "    v = now.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "    name = f'digits-recognizer-{v}'\n",
    "\n",
    "    isvc = V1beta1InferenceService(\n",
    "        api_version=f\"{constants.KSERVE_GROUP}/v1beta1\",\n",
    "        kind=constants.KSERVE_KIND,\n",
    "        metadata=client.V1ObjectMeta(\n",
    "            name=name,\n",
    "            namespace=namespace,\n",
    "            annotations={'sidecar.istio.io/inject':'false'}\n",
    "        ),\n",
    "        spec=V1beta1InferenceServiceSpec(\n",
    "            predictor=V1beta1PredictorSpec(\n",
    "                service_account_name=\"sa-minio-kserve\",\n",
    "                tensorflow=V1beta1TFServingSpec(\n",
    "                    storage_uri=\"s3://mlpipeline/models/detect-digits/\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    KServe = KServeClient()\n",
    "    KServe.create(isvc)\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='sdk01test',\n",
    "    description='Detect digits'\n",
    ")\n",
    "def sdk01test(no_epochs: int = 1, optimizer: str = \"adam\"):\n",
    "    data_batch = get_data_batch()\n",
    "    latest_data = get_latest_data()\n",
    "\n",
    "    reshape = reshape_data()\n",
    "    reshape.after(data_batch)\n",
    "    reshape.after(latest_data)\n",
    "\n",
    "    build = model_building(no_epochs=no_epochs, optimizer=optimizer)\n",
    "    build.after(reshape)\n",
    "\n",
    "    serve = model_serving()\n",
    "    serve.after(build)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from kfp import client\n",
    "\n",
    "    kfp_client = client.Client()\n",
    "\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=sdk01test,\n",
    "        package_path='pipeline.yaml'\n",
    "    )\n",
    "\n",
    "    "kfp_client.create_run_from_pipeline_func(\n",
  "    sdk01test,\n",
  "    arguments={\n",
  "        \"no_epochs\": 1,\n",
  "        \"optimizer\": \"user\"\n",
  "    },\n",
  "    experiment_name=\"sdk01test\",\n",
  "    run_name=\"sdk01test\"\n",
  ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
