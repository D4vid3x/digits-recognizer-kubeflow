from kfp import dsl, compiler
from typing import NamedTuple
from kfp.dsl import Input, Output, Dataset, Model, Artifact, component

@component(base_image="public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0")
def get_data_batch() -> NamedTuple('Outputs', [('datapoints_training', float),('datapoints_test', float),('dataset_version', str)]):
    from tensorflow import keras
    from minio import Minio
    import numpy as np
    import json

    minio_client = Minio(
        "100.65.11.110:9000",
        access_key="minio",
        secret_key="minio123",
        secure=False
    )
    minio_bucket = "mlpipeline"

    minio_client.fget_object(minio_bucket,"mnist.npz","/tmp/mnist.npz")

    def load_data():
        with np.load("/tmp/mnist.npz", allow_pickle=True) as f:
            x_train, y_train = f["x_train"], f["y_train"]
            x_test, y_test = f["x_test"], f["y_test"]
        return (x_train, y_train), (x_test, y_test)

    (x_train, y_train), (x_test, y_test) = load_data()

    np.save("/tmp/x_train.npy",x_train)
    minio_client.fput_object(minio_bucket,"x_train","/tmp/x_train.npy")

    np.save("/tmp/y_train.npy",y_train)
    minio_client.fput_object(minio_bucket,"y_train","/tmp/y_train.npy")

    np.save("/tmp/x_test.npy",x_test)
    minio_client.fput_object(minio_bucket,"x_test","/tmp/x_test.npy")

    np.save("/tmp/y_test.npy",y_test)
    minio_client.fput_object(minio_bucket,"y_test","/tmp/y_test.npy")

    dataset_version = "1.0"

    print(f"x_train shape: {x_train.shape}")
    print(f"y_train shape: {y_train.shape}")
    print(f"x_test shape: {x_test.shape}")
    print(f"y_test shape: {y_test.shape}")

    from collections import namedtuple
    divmod_output = namedtuple('Outputs', ['datapoints_training', 'datapoints_test', 'dataset_version'])
    return [float(x_train.shape[0]),float(x_test.shape[0]),dataset_version]

@component(base_image="public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0")
def get_latest_data():
    print("Adding latest data")

@component(base_image="public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0")
def reshape_data():
    from minio import Minio
    import numpy as np

    minio_client = Minio(
        "100.65.11.110:9000",
        access_key="minio",
        secret_key="minio123",
        secure=False
    )
    minio_bucket = "mlpipeline"

    minio_client.fget_object(minio_bucket,"x_train","/tmp/x_train.npy")
    x_train = np.load("/tmp/x_train.npy")

    minio_client.fget_object(minio_bucket,"x_test","/tmp/x_test.npy")
    x_test = np.load("/tmp/x_test.npy")

    x_train = x_train.reshape(-1,28,28,1)
    x_test = x_test.reshape(-1,28,28,1)

    x_train = x_train / 255
    x_test = x_test / 255

    np.save("/tmp/x_train.npy",x_train)
    minio_client.fput_object(minio_bucket,"x_train","/tmp/x_train.npy")

    np.save("/tmp/x_test.npy",x_test)
    minio_client.fput_object(minio_bucket,"x_test","/tmp/x_test.npy")

@component(base_image="public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0")
def model_building(no_epochs: int = 1, optimizer: str = "adam"):
    from tensorflow import keras
    import tensorflow as tf
    from minio import Minio
    import numpy as np
    import pandas as pd
    import json

    minio_client = Minio(
        "100.65.11.110:9000",
        access_key="minio",
        secret_key="minio123",
        secure=False
    )
    minio_bucket = "mlpipeline"

    model = keras.models.Sequential([
        keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),
        keras.layers.MaxPool2D(2, 2),
        keras.layers.Flatten(),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dense(10, activation='softmax')
    ])

    stringlist = []
    model.summary(print_fn=lambda x: stringlist.append(x))
    metric_model_summary = "\n".join(stringlist)

    model.compile(optimizer=optimizer,
                loss="sparse_categorical_crossentropy",
                metrics=['accuracy'])

    minio_client.fget_object(minio_bucket,"x_train","/tmp/x_train.npy")
    x_train = np.load("/tmp/x_train.npy")

    minio_client.fget_object(minio_bucket,"y_train","/tmp/y_train.npy")
    y_train = np.load("/tmp/y_train.npy")

    history = model.fit(x_train, y_train, epochs=no_epochs, batch_size=20)

    minio_client.fget_object(minio_bucket,"x_test","/tmp/x_test.npy")
    x_test = np.load("/tmp/x_test.npy")

    minio_client.fget_object(minio_bucket,"y_test","/tmp/y_test.npy")
    y_test = np.load("/tmp/y_test.npy")

    model_loss, model_accuracy = model.evaluate(x_test, y_test)

    test_predictions = model.predict(x_test)
    test_predictions = np.argmax(test_predictions, axis=1)

    confusion_matrix = tf.math.confusion_matrix(labels=y_test, predictions=test_predictions)
    confusion_matrix = confusion_matrix.numpy()
    vocab = list(np.unique(y_test))
    data = [(vocab[target_index], vocab[predicted_index], count)
            for target_index, target_row in enumerate(confusion_matrix)
            for predicted_index, count in enumerate(target_row)]

    df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])
    cm_csv = df_cm.to_csv(header=False, index=False)


    keras.models.save_model(model, "/tmp/detect-digits")

    def upload_local_directory_to_minio(local_path, bucket_name, minio_path):
        import os, glob
        assert os.path.isdir(local_path)
        for local_file in glob.glob(local_path + '/**'):
            local_file = local_file.replace(os.sep, "/")
            if not os.path.isfile(local_file):
                upload_local_directory_to_minio(local_file, bucket_name, f"{minio_path}/{os.path.basename(local_file)}")
            else:
                remote_path = os.path.join(minio_path, local_file[1 + len(local_path):]).replace(os.sep, "/")
                minio_client.fput_object(bucket_name, remote_path, local_file)

    upload_local_directory_to_minio("/tmp/detect-digits", minio_bucket, "models/detect-digits/1/")
    print("Saved model to minIO")

    from collections import namedtuple
    output = namedtuple('output', ['mlpipeline_ui_metadata', 'mlpipeline_metrics'])
    return output(json.dumps(metadata), json.dumps(metrics))

@component(base_image="public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0",
          packages_to_install=['kserve==0.8.0.1'])
def model_serving():
    from kubernetes import client
    from kserve import KServeClient
    from kserve import constants
    from kserve import utils
    from kserve import V1beta1InferenceService
    from kserve import V1beta1InferenceServiceSpec
    from kserve import V1beta1PredictorSpec
    from kserve import V1beta1TFServingSpec
    from datetime import datetime

    namespace = utils.get_default_target_namespace()
    now = datetime.now()
    v = now.strftime("%Y-%m-%d--%H-%M-%S")
    name = f'digits-recognizer-{v}'

    isvc = V1beta1InferenceService(
        api_version=f"{constants.KSERVE_GROUP}/v1beta1",
        kind=constants.KSERVE_KIND,
        metadata=client.V1ObjectMeta(
            name=name,
            namespace=namespace,
            annotations={'sidecar.istio.io/inject':'false'}
        ),
        spec=V1beta1InferenceServiceSpec(
            predictor=V1beta1PredictorSpec(
                service_account_name="sa-minio-kserve",
                tensorflow=V1beta1TFServingSpec(
                    storage_uri="s3://mlpipeline/models/detect-digits/"
                )
            )
        )
    )

    KServe = KServeClient()
    KServe.create(isvc)

@dsl.pipeline(
    name='digits-recognizer-pipeline',
    description='Detect digits'
)
def digits_recognizer_pipeline(no_epochs: int = 1, optimizer: str = "adam"):
    data_batch = get_data_batch()
    latest_data = get_latest_data()

    reshape = reshape_data()
    reshape.after(data_batch)
    reshape.after(latest_data)

    build = model_building(no_epochs=no_epochs, optimizer=optimizer)
    build.after(reshape)

    serve = model_serving()
    serve.after(build)

if __name__ == "__main__":
    from kfp import client

    kfp_client = client.Client()

    compiler.Compiler().compile(
        pipeline_func=digits_recognizer_pipeline,
        package_path='pipeline.yaml'
    )

    kfp_client.create_run_from_pipeline_func(
        digits_recognizer_pipeline,
        arguments={
            "no_epochs": 1,
            "optimizer": "adam"
        },
        experiment_name="digits-recognizer"
    )